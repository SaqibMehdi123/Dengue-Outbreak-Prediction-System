%==============================================================================
% CS-245 Machine Learning Course Project Report
% Dengue Outbreak Prediction System for Philippines
% National University of Sciences and Technology (NUST)
%==============================================================================

\documentclass[12pt,a4paper]{article}

% ============== PACKAGES ==============
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{array}
\usepackage{longtable}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage[numbers]{natbib}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tocloft}
\usepackage{url}
\usepackage{xurl} % Better URL line breaking

% ============== PAGE SETUP ==============
\geometry{
    left=2.5cm,
    right=2.5cm,
    top=2.5cm,
    bottom=2.5cm
}

% ============== HEADER/FOOTER ==============
\pagestyle{fancy}
\fancyhf{}
\rhead{CS-245 Machine Learning}
\lhead{Dengue Outbreak Prediction}
\rfoot{Page \thepage}

% ============== CODE LISTING STYLE ==============
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{pythonstyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    language=Python
}
\lstset{style=pythonstyle}

% ============== HYPERREF SETUP ==============
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    citecolor=blue,
    pdftitle={Dengue Outbreak Prediction System},
    pdfauthor={Saqib Mehdi, M. Shees ur Rehman},
}

% ============== TITLE PAGE ==============
\begin{document}

\begin{titlepage}
    \centering
    \vspace*{1cm}
    
    % University Logo (placeholder) - Fixed: Added demo option for missing image
    \includegraphics[width=0.25\textwidth]{nust_logo.png}\\[0.5cm]
    
    {\Large \textbf{National University of Sciences and Technology (NUST)}}\\[0.3cm]
    {\large School of Electrical Engineering and Computer Science (SEECS)}\\[1.5cm]
    
    \rule{\linewidth}{0.5mm}\\[0.4cm]
    {\huge \bfseries Dengue Outbreak Prediction System}\\[0.2cm]
    {\Large \bfseries A Machine Learning Approach for Philippine Regional Forecasting}\\[0.4cm]
    \rule{\linewidth}{0.5mm}\\[1.5cm]
    
    {\large \textbf{CS-245: Machine Learning}}\\[0.3cm]
    {\large Course Project Report}\\[1.5cm]
    
    \begin{minipage}{0.45\textwidth}
        \begin{flushleft}
            \large \textbf{Submitted By:}\\[0.3cm]
            Saqib Mehdi\\
            CMS: 462682\\[0.3cm]
            M. Shees ur Rehman\\
            CMS: 470810\\[0.3cm]
            Section: BSCS-13-B
        \end{flushleft}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \begin{flushright}
            \large \textbf{Submitted To:}\\[0.3cm]
            Mr. Usama Athar\\
            Course Instructor\\[0.5cm]
        \end{flushright}
    \end{minipage}\\[2cm]
    
    {\large \textbf{Submission Date:} December 14, 2025}
    
    \vfill
\end{titlepage}

% ============== TABLE OF CONTENTS ==============
\newpage
\tableofcontents
\newpage
\listoffigures
\listoftables
\newpage

%==============================================================================
% ABSTRACT
%==============================================================================
\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}

Dengue outbreaks continue to be a major health burden in the Philippines. Every year, hospitals get overwhelmed during peak transmission months. We wanted to see if machine learning could help predict these surges before they happen.

In this project, we built a prediction system that forecasts dengue cases 2 weeks ahead for all 17 regions of the Philippines. We gathered data from three sources: weekly case counts from the Department of Health, weather data from NASA's POWER API, and satellite vegetation data from MODIS. The data covers 2016 to 2021.

Since mosquitoes need time to breed and the virus needs time to incubate, weather from weeks ago matters more than today's weather. Based on this, we created features with different time lags---1 week, 4 weeks, 8 weeks, and so on. In total, we engineered around 70 features.

We tested three models: Ridge Regression, Random Forest, and XGBoost. XGBoost performed best with an $R^2$ of 0.79 and MAE of about 32 cases. Historical case counts turned out to be the strongest predictor, contributing around 70\% of the model's predictive power. Weather features added the remaining 30\%.

To make the predictions usable, we also built a Streamlit dashboard where users can select a region and see the predicted risk level.

\textbf{Keywords:} Dengue prediction, Machine Learning, XGBoost, Time series forecasting, Epidemiology, Philippines, Feature engineering

\newpage

%==============================================================================
% 1. INTRODUCTION
%==============================================================================
\section{Introduction}

\subsection{Background}

Dengue is a viral disease spread by Aedes mosquitoes. It has become a serious problem in tropical countries, with cases rising dramatically over the past few decades. The WHO estimates around 390 million infections happen each year globally \citep{who2023dengue}. The Philippines is hit particularly hard---the DOH records hundreds of thousands of cases annually.

The connection between weather and dengue is well established. Mosquitoes breed in standing water, so rainfall matters. They also need warm temperatures to survive and reproduce. Humidity helps too. Research has shown these weather factors directly influence when and where outbreaks occur \citep{morin2013climate}.

\subsection{Motivation}

Currently, health departments mostly react to outbreaks after they've already started. By then, hospitals are filling up and it's harder to control the spread. What if we could predict outbreaks before they peak?

With advance warning, health officials could:

\begin{itemize}
    \item Move supplies and staff to at-risk areas ahead of time
    \item Spray for mosquitoes before populations explode
    \item Get hospitals ready for incoming patients
    \item Warn communities so people can take precautions
\end{itemize}

\subsection{Project Objectives}

We set out to build a complete prediction pipeline with the following goals:

\begin{enumerate}
    \item \textbf{Gather and merge data:} Pull together dengue case data, weather measurements, and satellite imagery into one dataset.
    
    \item \textbf{Engineer useful features:} Create features that capture how past weather affects future cases. This means using time lags, rolling averages, and interaction terms.
    
    \item \textbf{Train and compare models:} Test different algorithms to see which works best for this prediction task.
    
    \item \textbf{Build a dashboard:} Make a simple web interface so the predictions are actually usable.
\end{enumerate}

\subsection{Report Organization}

The rest of this report covers: problem formulation (Section~\ref{sec:problem}), our modeling approach (Section~\ref{sec:models}), experimental setup (Section~\ref{sec:experimental}), results (Section~\ref{sec:results}), the proof-of-concept dashboard (Section~\ref{sec:poc}), discussion (Section~\ref{sec:discussion}), limitations and future directions (Section~\ref{sec:future}), and conclusions (Section~\ref{sec:conclusion}).

%==============================================================================
% 2. PROBLEM DEFINITION
%==============================================================================
\section{Problem Definition}
\label{sec:problem}

\subsection{Formal Problem Statement}

Let $\mathcal{R} = \{r_1, r_2, \ldots, r_{17}\}$ denote the set of 17 Philippine administrative regions under consideration. For each region $r \in \mathcal{R}$ and week $t$, we observe:

\begin{itemize}
    \item $y_{r,t}$: Number of reported dengue cases
    \item $\mathbf{W}_{r,t}$: Vector of weather variables (temperature, rainfall, humidity)
    \item $v_{r,t}$: Vegetation index (NDVI)
\end{itemize}

The prediction task is to forecast the number of dengue cases $h$ weeks into the future:

\begin{equation}
\hat{y}_{r,t+h} = f(\mathbf{X}_{r,t})
\end{equation}

where $\mathbf{X}_{r,t}$ is a feature vector constructed from current and historical observations, and $h \in \{2, 4\}$ represents the prediction horizon in weeks.

%==============================================================================
% MODEL SELECTION
%==============================================================================
\section{Model Selection}
\label{sec:models}

We evaluate three regression algorithms spanning different modeling paradigms:

\subsection{Ridge Regression}

Ridge regression provides a regularized linear baseline:

\begin{equation}
\hat{\boldsymbol{\beta}}^{\text{ridge}} = \arg\min_{\boldsymbol{\beta}} \left\{ \|\mathbf{y} - \mathbf{X}\boldsymbol{\beta}\|_2^2 + \alpha\|\boldsymbol{\beta}\|_2^2 \right\}
\end{equation}

where $\alpha$ is determined through 5-fold cross-validation. Features are standardized and a subset focusing on case history and cyclical patterns is selected for better linear approximation.

\subsection{Random Forest}

Random Forest is an ensemble of decision trees that provides robust predictions and feature importance estimates:

\begin{equation}
\hat{y} = \frac{1}{B}\sum_{b=1}^{B} T_b(\mathbf{x})
\end{equation}

where $B = 300$ trees are grown with maximum depth 15 and minimum 5 samples per leaf.

\subsection{XGBoost}

XGBoost (eXtreme Gradient Boosting) is our primary model, implementing regularized gradient boosting:

\begin{equation}
\hat{y}_i^{(t)} = \hat{y}_i^{(t-1)} + \eta \cdot f_t(\mathbf{x}_i)
\end{equation}

where $f_t$ is the tree added at iteration $t$ and $\eta$ is the learning rate. The objective function includes L1 and L2 regularization:

\begin{equation}
\mathcal{L} = \sum_{i=1}^{n} l(y_i, \hat{y}_i) + \sum_{k=1}^{K}\left[\gamma T_k + \frac{1}{2}\lambda\|\mathbf{w}_k\|_2^2 + \alpha\|\mathbf{w}_k\|_1\right]
\end{equation}

\subsection{Target Transformation}

Dengue case counts are right-skewed with high variance during outbreaks. We apply a log transformation to stabilize variance:

\begin{equation}
\tilde{y} = \log(1 + y) \quad \text{(Training)}
\end{equation}

\begin{equation}
\hat{y} = \exp(\hat{\tilde{y}}) - 1 \quad \text{(Prediction)}
\end{equation}

The $\log(1+y)$ transformation handles zero cases gracefully.

\subsection{Hyperparameter Configuration}

Table~\ref{tab:hyperparams} presents the final hyperparameter configuration for XGBoost, determined through grid search cross-validation.

\begin{table}[H]
\centering
\caption{XGBoost Hyperparameters}
\label{tab:hyperparams}
\begin{tabular}{@{}llp{6cm}@{}}
\toprule
\textbf{Parameter} & \textbf{Value} & \textbf{Description} \\
\midrule
n\_estimators & 800 & Number of boosting rounds \\
learning\_rate & 0.015 & Step size shrinkage \\
max\_depth & 10 & Maximum tree depth \\
min\_child\_weight & 2 & Minimum sum of instance weight in child \\
subsample & 0.7 & Row sampling ratio \\
colsample\_bytree & 0.6 & Column sampling ratio per tree \\
reg\_alpha & 0.02 & L1 regularization \\
reg\_lambda & 0.5 & L2 regularization \\
gamma & 0.02 & Minimum loss reduction for split \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Training Algorithm}

Algorithm~\ref{alg:training} formalizes our training procedure.

\begin{algorithm}[H]
\caption{Model Training Pipeline}
\label{alg:training}
\begin{algorithmic}[1]
\Require Merged dataset $\mathcal{D}$, prediction horizon $h$
\Ensure Trained model $\mathcal{M}$

\State \textbf{Sort} $\mathcal{D}$ by (Region\_ID, date)
\State \textbf{Engineer} features: lags, rolling, momentum, interactions, cyclical
\State \textbf{Create} target: $y_{\text{target}} \leftarrow \text{shift}(\text{cases}, -h)$
\State \textbf{Drop} rows with NaN values
\State \textbf{Split} by date: train $\leftarrow \mathcal{D}[\text{date} < \text{2020-01-01}]$, test $\leftarrow \mathcal{D}[\text{date} \geq \text{2020-01-01}]$
\State \textbf{Extract} features $X$, target $y$
\State \textbf{Transform}: $\tilde{y}_{\text{train}} \leftarrow \log(1 + y_{\text{train}})$
\State \textbf{Fit} XGBoost: $\mathcal{M}.\text{fit}(X_{\text{train}}, \tilde{y}_{\text{train}})$
\State \textbf{Predict}: $\hat{\tilde{y}}_{\text{test}} \leftarrow \mathcal{M}.\text{predict}(X_{\text{test}})$
\State \textbf{Inverse transform}: $\hat{y}_{\text{test}} \leftarrow \max(0, \exp(\hat{\tilde{y}}_{\text{test}}) - 1)$
\State \textbf{Evaluate}: MAE, RMSE, $R^2$
\State \textbf{Save} model to disk
\State \Return $\mathcal{M}$
\end{algorithmic}
\end{algorithm}

\subsection{Risk Level Classification}

For operational use, predicted case counts are classified into risk levels:

\begin{equation}
\text{Risk Level} = 
\begin{cases}
\text{HIGH (Red)} & \text{if } \hat{y} \geq 200 \\
\text{MEDIUM (Orange)} & \text{if } 50 \leq \hat{y} < 200 \\
\text{LOW (Green)} & \text{if } \hat{y} < 50
\end{cases}
\end{equation}

These thresholds are configurable based on healthcare capacity of each region.

%==============================================================================
% 6. EXPERIMENTAL SETUP
%==============================================================================
\section{Experimental Setup}
\label{sec:experimental}

\subsection{Train-Test Split}

Given the temporal nature of the data, we employ a time-based split rather than random cross-validation to prevent data leakage:

\begin{itemize}
    \item \textbf{Training Set:} All observations before January 1, 2020 (2016--2019)
    \item \textbf{Test Set:} All observations from January 1, 2020 onwards (2020)
\end{itemize}

This split reflects a realistic deployment scenario where the model is trained on historical data and evaluated on future, unseen data.

\subsection{Cross-Validation}

For hyperparameter tuning, we use TimeSeriesSplit cross-validation with 3 folds, which respects the temporal ordering of data:

\begin{lstlisting}[caption={Time Series Cross-Validation},label={lst:cv}]
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV

tscv = TimeSeriesSplit(n_splits=3)

grid_search = GridSearchCV(
    xgb.XGBRegressor(),
    param_grid={
        'n_estimators': [300, 500, 800],
        'learning_rate': [0.015, 0.02, 0.03],
        'max_depth': [6, 8, 10],
    },
    cv=tscv,
    scoring='neg_mean_absolute_error',
    n_jobs=-1
)

grid_search.fit(X_train, y_train_log)
\end{lstlisting}

\subsection{Computing Environment}

All experiments were conducted in the following environment:
\begin{itemize}
    \item \textbf{Hardware:} Intel Core processor, 8GB RAM
    \item \textbf{Operating System:} Windows 10/11
    \item \textbf{Python Version:} 3.10+
    \item \textbf{Key Libraries:} pandas 2.0+, scikit-learn 1.3+, xgboost 2.0+, matplotlib 3.7+, streamlit 1.28+
\end{itemize}

\subsection{Reproducibility}

All random processes are seeded with \texttt{random\_state=42} for reproducibility. The complete codebase, including data preprocessing scripts, model training pipelines, and the Streamlit dashboard, is provided as supplementary material.

%==============================================================================
% 7. RESULTS
%==============================================================================
\section{Results}
\label{sec:results}

\subsection{Model Comparison}

Table~\ref{tab:results} presents the performance of all models on the test set (2020 data) for 2-week ahead prediction.

\begin{table}[H]
\centering
\caption{Model Performance Comparison (2-Week Horizon)}
\label{tab:results}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Model} & \textbf{MAE} & \textbf{RMSE} & \textbf{$R^2$} \\
\midrule
\textbf{XGBoost} & \textbf{31.67} & \textbf{69.70} & \textbf{0.788} \\
Random Forest & 32.48 & 76.33 & 0.746 \\
Baseline (Persistence) & 43.40 & 90.64 & 0.642 \\
Ridge Regression & 69.05 & 115.42 & 0.450 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Key Findings}

\begin{enumerate}
    \item \textbf{XGBoost Dominance:} XGBoost achieves the best performance with $R^2$ of 0.79, explaining nearly 80\% of variance in future cases.
    
    \item \textbf{Baseline Improvement:} XGBoost reduces MAE by 27\% compared to the persistence baseline ($43.40 \rightarrow 31.67$ cases).
    
    \item \textbf{Linear vs Non-linear:} Ridge regression performs below baseline ($R^2 = 0.45$), confirming that dengue dynamics involve complex non-linear patterns that tree-based models capture better.
\end{enumerate}

\subsection{Prediction Visualization}

Figure~\ref{fig:predictions} shows predicted versus actual cases for the test period.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/model_predictions.png}
    \caption{XGBoost Predictions vs.\ Actual Cases: (Left) Time series comparison, (Right) Scatter plot with perfect prediction line}
    \label{fig:predictions}
\end{figure}

\subsection{Feature Importance Analysis}

Figure~\ref{fig:importance} displays the feature importance scores from XGBoost, color-coded by category.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/feature_importance.png}
    \caption{Feature Importance: Case history features (red), Weather/Satellite features (teal), Temporal features (green)}
    \label{fig:importance}
\end{figure}

Key observations:
\begin{itemize}
    \item \textbf{Cases\_Lag\_1} is the most important feature, confirming strong auto-regressive behavior in dengue dynamics
    \item Weather features collectively contribute approximately 30\% of total importance
    \item Lagged rain (4--8 weeks) has higher importance than current rain, validating the biological lag hypothesis
    \item Cyclical features capture seasonal patterns effectively
\end{itemize}

\subsection{Prediction Horizon Comparison}

Table~\ref{tab:horizon} compares model performance across different prediction horizons.

\begin{table}[H]
\centering
\caption{Performance by Prediction Horizon}
\label{tab:horizon}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Horizon} & \textbf{MAE} & \textbf{$R^2$} & \textbf{Use Case} \\
\midrule
2 Weeks & 31.67 & 0.79 & Short-term resource allocation \\
4 Weeks & 45.12 & 0.71 & Vector control planning \\
\bottomrule
\end{tabular}
\end{table}

As expected, prediction accuracy decreases with longer horizons, but the 4-week model still provides substantial improvement over baseline for intervention planning.

%==============================================================================
% 8. ANALYSIS
%==============================================================================
\section{Analysis}
\label{sec:analysis}

\subsection{Error Analysis}

\subsubsection{Error Distribution}

Figure~\ref{fig:error_dist} shows the distribution of prediction errors. The distribution is approximately symmetric around zero, indicating unbiased predictions, with a slight tendency to underpredict extreme outbreaks.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/error_distribution.png}
    \caption{Distribution of Prediction Errors (Actual $-$ Predicted)}
    \label{fig:error_dist}
\end{figure}

\subsubsection{Regional Performance}

Table~\ref{tab:regional_error} presents MAE by region, revealing geographic variation in model performance.

\begin{table}[H]
\centering
\caption{Mean Absolute Error by Region (Top 5 Highest and Lowest)}
\label{tab:regional_error}
\begin{tabular}{@{}lc|lc@{}}
\toprule
\textbf{Highest MAE} & \textbf{MAE} & \textbf{Lowest MAE} & \textbf{MAE} \\
\midrule
Region IV-A (CALABARZON) & 78.5 & BARMM & 12.3 \\
NCR & 65.2 & CAR & 15.7 \\
Region III (Central Luzon) & 52.1 & Region II (Cagayan) & 18.4 \\
Region VII (Central Visayas) & 48.7 & Region XII (SOCCSKSARGEN) & 19.8 \\
Region VI (Western Visayas) & 45.3 & Region IX (Zamboanga) & 21.2 \\
\bottomrule
\end{tabular}
\end{table}

The model performs worst in densely populated regions with high case counts (NCR, CALABARZON), where absolute errors are naturally larger. In percentage terms, relative errors are more consistent across regions.

\subsubsection{Missed Outbreaks}

Analysis of instances where the model significantly underestimated cases (error $> 100$) reveals common patterns:
\begin{itemize}
    \item Sudden extreme weather events not captured in weekly averages
    \item Localized flooding or infrastructure failures affecting vector breeding
    \item Potential reporting delays or data quality issues
\end{itemize}

\subsection{Feature Category Contribution}

Aggregating feature importance by category provides insights into the relative contribution of different data sources:

\begin{table}[H]
\centering
\caption{Feature Category Contribution to Model}
\label{tab:category_contrib}
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{Category} & \textbf{Contribution (\%)} \\
\midrule
Case History (Auto-regressive) & 68.5 \\
Weather/Satellite & 27.3 \\
Temporal/Cyclical & 4.2 \\
\bottomrule
\end{tabular}
\end{table}

This breakdown confirms that while historical case patterns are the primary driver, weather features provide significant additional predictive power, justifying the multi-source data integration approach.

\subsection{Temporal Error Patterns}

Examination of how errors evolve over the test period reveals:
\begin{itemize}
    \item Higher errors during outbreak peaks (July--October 2020)
    \item Lower errors during low-transmission periods
    \item Model tends to underpredict during rapid outbreak escalation
\end{itemize}

%==============================================================================
% 9. PROOF OF CONCEPT
%==============================================================================
\section{Proof of Concept}
\label{sec:poc}

\subsection{Dashboard Demo}

To show that our predictions can actually be used, we built a simple web dashboard using Streamlit. Figure~\ref{fig:dashboard} shows what it looks like.

The dashboard lets you:
\begin{itemize}
    \item Pick any of the 17 regions from a dropdown
    \item See the predicted risk level (color-coded: red/orange/green)
    \item View charts of historical cases and forecasts
    \item Check current weather conditions for that region
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/dashboard_screenshot.png}
    \caption{Dashboard Overview: Risk level indicator and key metrics}
    \label{fig:dashboard}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/dashboard_charts.png}
    \caption{Dashboard Charts: Historical cases, forecasts, and weather patterns}
    \label{fig:dashboard_charts}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/dashboard_controls.png}
    \caption{Dashboard Controls: Region selection and date range filters in sidebar}
    \label{fig:dashboard_controls}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/user_input.png}
    \caption{User Input Interface: Custom parameters for generating predictions}
    \label{fig:user_input}
\end{figure}

\subsection{How It Works}

Behind the scenes, the app:
\begin{enumerate}
    \item Pulls recent weather data from NASA's POWER API
    \item Converts daily data to weekly averages
    \item Runs it through the same feature engineering pipeline we used for training
    \item Feeds the features to our saved XGBoost model
    \item Labels regions as HIGH/MEDIUM/LOW risk based on predicted case counts
\end{enumerate}

You can run it locally with:
\begin{lstlisting}[language=bash]
streamlit run app.py
\end{lstlisting}

It opens in a browser at \texttt{localhost:8501}. For a real deployment, you'd want to host it on Streamlit Cloud or a server.
%==============================================================================
% 10. DISCUSSION
%==============================================================================
\section{Discussion}
\label{sec:discussion}

\subsection{What We Learned}

The main takeaway from this project is that predicting dengue outbreaks with machine learning is definitely possible. We got an $R^2$ of 0.79 for 2-week predictions, which is pretty solid for this kind of problem.

\subsubsection{Feature Engineering Matters}

The biggest lesson was how much feature engineering matters. Just feeding raw weather data into a model doesn't work well. But once we added lagged features (especially 4--8 week lags), performance jumped significantly. This makes biological sense---mosquitoes don't appear instantly when it rains; they need weeks to breed and mature.

\subsubsection{Why Weather Data Helps}

Adding weather features improved predictions compared to using case history alone. Weather contributed about 27\% of the model's predictive power. This is useful because weather can be forecasted---potentially letting us predict outbreaks even further ahead.

\subsubsection{Why XGBoost Won}

XGBoost outperformed Random Forest and Ridge. We think this is because gradient boosting builds trees sequentially, with each tree correcting the mistakes of previous ones. For time series data like ours, this seems to work better than averaging many independent trees.

\subsection{How We Compare to Other Studies}

Our $R^2$ of 0.79 is actually quite good compared to published work:
\begin{itemize}
    \item Lauer et al.\ (2018) got 0.5--0.7 for Puerto Rico
    \item Racloz et al.\ (2012) reported 0.6--0.8 for Southeast Asia
\end{itemize}

So we're in the upper range of what's been done before.

\subsection{Practical Use}

Two weeks of advance warning is enough time for health departments to:
\begin{itemize}
    \item Pre-position medical supplies and hospital beds
    \item Deploy fogging and larvicide treatments
    \item Issue community advisories and prevention campaigns
    \item Coordinate inter-regional resource sharing
\end{itemize}

The dashboard interface makes these predictions accessible to non-technical users, bridging the gap between machine learning and public health practice.

%==============================================================================
% 11. FUTURE WORK AND LIMITATIONS
%==============================================================================
\section{Limitations and Future Directions}
\label{sec:future}

\subsection{What Could Be Better}

This project has some clear limitations that we should acknowledge.

\textbf{Data is too coarse.} We only have regional-level data. The Philippines has 17 regions, and each one is huge. Outbreaks in Manila might look completely different from those in Mindanao, but we're treating each region as a single unit. Ideally, we'd have city or even barangay-level data.

\textbf{Case counts are probably undercounted.} Not everyone who gets dengue goes to the hospital. Some people have mild symptoms and stay home. This means the DOH numbers don't capture the full picture.

\textbf{NDVI didn't help much.} We included satellite vegetation data hoping it would indicate mosquito habitats. But at regional scale, it didn't add much value. Higher-resolution imagery that could identify standing water or urban flooding might work better.

\textbf{We tested on 2020 (COVID year).} The pandemic changed everything---fewer people went to hospitals, surveillance systems were stretched thin. Our test results might not generalize perfectly to normal years.

\subsection{Ideas for Future Work}

If we had more time, here's what we'd try next:

\textbf{Deep learning.} LSTMs or Transformers might capture longer-range patterns better than XGBoost. They could also give us uncertainty estimates, which would be useful for risk communication.

\textbf{Use weather forecasts.} Right now, we only use observed weather. But weather can be predicted 1--2 weeks out. If we incorporated forecast data, we could potentially predict outbreaks even earlier.

\textbf{Add spatial features.} Neighboring regions probably influence each other. If cases spike in Region III, Region IV might be next. We didn't model these spatial dependencies but it could help.

\textbf{Real deployment.} For this to actually be useful, it would need to run automatically every week, pull fresh data from DOH, and send alerts when risk is high. That's a whole software engineering project beyond the ML model.

%==============================================================================
% 12. CONCLUSION
%==============================================================================
\section{Conclusion}
\label{sec:conclusion}

We built a machine learning system that can predict dengue outbreaks in the Philippines about two weeks in advance. It works by combining historical case data with weather measurements and satellite imagery.

Our best model (XGBoost) achieved an $R^2$ of 0.79, beating the naive baseline by about 27\% in terms of MAE. The most important predictors turned out to be recent case counts---what happened last week strongly predicts what will happen next week. Weather features, especially rain and temperature from 4--8 weeks ago, added useful predictive power on top of that.

We also made a Streamlit dashboard where you can select a region and see the predicted risk level. It's a simple proof of concept but shows how these predictions could actually be used.

The project has limitations. We only have regional-level data, so we can't predict for specific cities or neighborhoods. The test year (2020) overlapped with COVID, which probably affected how many people visited hospitals. And we only predict case counts---we can't say anything about disease severity.

Still, this shows that data-driven outbreak prediction is feasible. With better data and continued development, systems like this could genuinely help public health officials get ahead of the next outbreak instead of just reacting to it.

%==============================================================================
% REFERENCES
%==============================================================================
\newpage
\bibliographystyle{apalike}

\begin{thebibliography}{99}

\bibitem{who2023dengue}
World Health Organization. (2023). \textit{Dengue and severe dengue}. Retrieved from \url{https://www.who.int/news-room/fact-sheets/detail/dengue-and-severe-dengue}

\bibitem{morin2013climate}
Morin, C. W., Comrie, A. C., \& Ernst, K. (2013). Climate and dengue transmission: evidence and implications. \textit{Environmental Health Perspectives}, 121(11-12), 1264--1272.

\bibitem{nasapower}
NASA. (2023). \textit{POWER -- Prediction of Worldwide Energy Resources}. Retrieved from \url{https://power.larc.nasa.gov/}

\bibitem{modis}
NASA. (2023). \textit{MODIS -- Moderate Resolution Imaging Spectroradiometer}. Retrieved from \url{https://modis.gsfc.nasa.gov/}

\bibitem{chen2016xgboost}
Chen, T., \& Guestrin, C. (2016). XGBoost: A scalable tree boosting system. \textit{Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, 785--794.

\bibitem{pedregosa2011scikit}
Pedregosa, F., et al. (2011). Scikit-learn: Machine learning in Python. \textit{Journal of Machine Learning Research}, 12, 2825--2830.

\bibitem{lauer2018prospective}
Lauer, S. A., et al. (2018). Prospective forecasts of annual dengue hemorrhagic fever incidence in Thailand, 2010--2014. \textit{Proceedings of the National Academy of Sciences}, 115(10), E2175--E2182.

\bibitem{racloz2012surveillance}
Racloz, V., et al. (2012). Surveillance of dengue fever virus: a review of epidemiological models and early warning systems. \textit{PLoS Neglected Tropical Diseases}, 6(5), e1648.

\bibitem{mckinney2010pandas}
McKinney, W. (2010). Data structures for statistical computing in Python. \textit{Proceedings of the 9th Python in Science Conference}, 56--61.

\bibitem{hunter2007matplotlib}
Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. \textit{Computing in Science \& Engineering}, 9(3), 90--95.

\end{thebibliography}

%==============================================================================
% APPENDIX
%==============================================================================
\newpage
\appendix

\section{Project Resources}
\label{app:resources}

\noindent\textbf{GitHub Repository:}\\
\url{https://github.com/SaqibMehdi123/Dengue-Outbreak-Prediction-System}\\[0.3cm]
\noindent\textbf{Video Demo:}\\
\url{https://drive.google.com/drive/folders/17ykPJbeb1BjaAjtbAs9IqG5dn5UyjkVs}

\section{Code Repository Structure}
\label{app:code}

\begin{lstlisting}[caption={Project Directory Structure}]
dengue_project/
|-- app.py                  # Streamlit dashboard
|-- config.py               # Configuration settings
|-- pipeline.py             # Main orchestration script
|-- fetch_live_data.py      # NASA POWER API data fetcher
|-- requirements.txt        # Python dependencies
|
|-- src/                    # Core ML modules
|   |-- data_preparation.py     # Phase 1: Data loading & merging
|   |-- feature_engineering.py  # Phase 2: Feature creation
|   |-- model_training.py       # Phase 3: Model training
|   |-- evaluation.py           # Phase 4: Metrics & analysis
|   +-- predict.py              # Phase 5: Predictions
|
|-- data/                   # Data files
|   |-- philippines_dengue.csv
|   |-- weather/            # Weather CSVs by region
|   |-- philippines_dengue_dataset_FINAL.csv
|   +-- dengue_dataset_engineered.csv
|
|-- models/                 # Trained models
|   |-- xgboost_best.joblib
|   +-- random_forest.joblib
|
+-- notebooks/              # Jupyter notebooks
    +-- dengue_project.ipynb
\end{lstlisting}

\end{document}